{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Tensor Operations for Deep Learning\n",
    "\n",
    "This notebook demonstrates **real-world applications** of tensor operations in deep learning.\n",
    "\n",
    "## Topics Covered\n",
    "\n",
    "1. **Boolean Masking** - Attention masks, padding, data filtering\n",
    "2. **Data Preprocessing** - Normalization, standardization\n",
    "3. **Feature Engineering** - Polynomial features, time features\n",
    "4. **Batch Operations** - Variable-length sequences, efficient batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from pytorch_lab.tensor_ops import (\n",
    "    BooleanMasking,\n",
    "    create_attention_mask,\n",
    "    DataPreprocessor,\n",
    "    normalize_features,\n",
    "    FeatureEngineer,\n",
    "    create_polynomial_features,\n",
    "    BatchOperations,\n",
    ")\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Boolean Masking for Transformers\n",
    "\n",
    "**Problem**: Sentences have different lengths, but we need fixed-size batches.\n",
    "\n",
    "**Solution**: Pad sequences and use attention masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch of 3 sentences with different lengths\n",
    "sentence_lengths = torch.tensor([5, 3, 7])\n",
    "max_length = 10\n",
    "\n",
    "mask = create_attention_mask(sentence_lengths, max_length)\n",
    "print(\"Attention Mask:\")\n",
    "print(mask)\n",
    "print(\"\\nTrue = real token, False = padding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Filtering Outliers\n",
    "\n",
    "**Problem**: Sensor data contains errors and anomalies.\n",
    "\n",
    "**Solution**: Use boolean masking to filter outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate sensor data with outliers\n",
    "normal_data = torch.randn(95, 3) * 10 + 50\n",
    "outliers = torch.tensor([[999.0, 50.0, 45.0], [48.0, -999.0, 52.0]])\n",
    "data = torch.cat([normal_data, outliers], dim=0)\n",
    "\n",
    "clean_data, mask = BooleanMasking.filter_outliers(data, n_std=3.0)\n",
    "print(f\"Original: {len(data)} samples\")\n",
    "print(f\"Cleaned: {len(clean_data)} samples\")\n",
    "print(f\"Removed: {(~mask).sum()} outliers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Data Normalization\n",
    "\n",
    "**Problem**: Features have different scales (age: 0-100, income: 0-1M).\n",
    "\n",
    "**Solution**: Normalize or standardize features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features on different scales\n",
    "age = torch.rand(1000) * 60 + 20\n",
    "income = torch.rand(1000) * 180000 + 20000\n",
    "data = torch.stack([age, income], dim=1)\n",
    "\n",
    "print(\"Original:\")\n",
    "print(f\"Age: mean={age.mean():.1f}, std={age.std():.1f}\")\n",
    "print(f\"Income: mean={income.mean():.1f}, std={income.std():.1f}\")\n",
    "\n",
    "# Normalize to [0, 1]\n",
    "normalized = normalize_features(data, dim=0)\n",
    "print(\"\\nNormalized to [0, 1]:\")\n",
    "print(f\"Range: [{normalized.min():.3f}, {normalized.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Proper Train-Test Preprocessing\n",
    "\n",
    "**Critical**: Fit preprocessing on training data only!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.randn(1000, 5) * 10 + 50\n",
    "train_data = data[:800]\n",
    "test_data = data[800:]\n",
    "\n",
    "# Fit on train only\n",
    "preprocessor = DataPreprocessor()\n",
    "preprocessor.fit_standardize(train_data, dim=0)\n",
    "\n",
    "# Transform both\n",
    "train_std = preprocessor.standardize(train_data)\n",
    "test_std = preprocessor.standardize(test_data)\n",
    "\n",
    "print(\"Train mean:\", train_std.mean(dim=0).numpy())\n",
    "print(\"Test mean:\", test_std.mean(dim=0).numpy())\n",
    "print(\"\\n✓ Test mean is NOT exactly 0 - this is correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Polynomial Features\n",
    "\n",
    "**Problem**: Linear models can't capture non-linear relationships.\n",
    "\n",
    "**Solution**: Add polynomial features (x²,x³, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(-3, 3, 100).unsqueeze(1)\n",
    "y = 0.5 * x**2 + 0.3 * x + torch.randn(100, 1) * 0.5\n",
    "\n",
    "x_poly = create_polynomial_features(x, degree=3)\n",
    "print(f\"Original features: {x.shape}\")\n",
    "print(f\"With polynomial (degree=3): {x_poly.shape}\")\n",
    "print(\"Features: x, x², x³\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Handling Variable-Length Sequences\n",
    "\n",
    "**Problem**: Text/time series have different lengths.\n",
    "\n",
    "**Solution**: Pad sequences for batching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable-length sequences\n",
    "sequences = [\n",
    "    torch.randn(5, 10),  # Length 5\n",
    "    torch.randn(3, 10),  # Length 3\n",
    "    torch.randn(7, 10),  # Length 7\n",
    "]\n",
    "\n",
    "padded, lengths = BatchOperations.pad_sequences(sequences)\n",
    "print(f\"Padded shape: {padded.shape}\")\n",
    "print(f\"Original lengths: {lengths.tolist()}\")\n",
    "print(\"\\n✓ All sequences now have same length for batching\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Boolean Masking Use Cases\n",
    "- **Transformers**: Attention masks for padded sequences\n",
    "- **Data Cleaning**: Filter outliers and invalid values\n",
    "- **Feature Selection**: Select top-k important features\n",
    "\n",
    "### Preprocessing Use Cases\n",
    "- **Normalization**: Scale features to [0,1] for bounded outputs\n",
    "- **Standardization**: Zero mean, unit variance for gradient descent\n",
    "- **Train-Test Split**: Always fit on train, transform both\n",
    "\n",
    "### Feature Engineering Use Cases\n",
    "- **Polynomial Features**: Capture non-linear patterns\n",
    "- **Time Features**: Cyclical encoding for periodic data\n",
    "- **Interaction Features**: Capture feature relationships\n",
    "\n",
    "### Batch Operations Use Cases\n",
    "- **Padding**: Handle variable-length sequences\n",
    "- **Collation**: Custom batching for DataLoader\n",
    "- **Stratified Split**: Maintain class balance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
